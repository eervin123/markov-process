{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import vectorbtpro as vbt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "vbt.settings.set_theme(\"dark\")\n",
    "vbt.settings.plotting[\"layout\"][\"width\"] = 800\n",
    "vbt.settings.plotting['layout']['height'] = 200\n",
    "\n",
    "import pandas_ta as ta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_90M_db_vbt = vbt.BinanceData.load('data/btc_90M_db_vbt.pkl')\n",
    "\n",
    "data = btc_90M_db_vbt['2021-01-01':'2023-01-01']\n",
    "outofsample_data = btc_90M_db_vbt['2023-01-01':'2023-06-03']\n",
    "print(data.shape)\n",
    "print(outofsample_data.shape)\n",
    "# Wherever you saved the pickle file\n",
    "data_path = '/Users/ericervin/Documents/Coding/data-repository/data/fixed_BTCUSDT.csv'\n",
    "# min_data = vbt.BinanceData.from_csv(data_path)\n",
    "# print(min_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_df = data.get()\n",
    "markov_df['pct_change'] = markov_df['Close'].pct_change()\n",
    "markov_df['log_ret'] = np.log(markov_df['Close']).diff()\n",
    "markov_df['volatility'] = markov_df['log_ret'].rolling(100).std() * np.sqrt(100)\n",
    "markov_df['volume_chg'] = markov_df['Volume'].pct_change()\n",
    "markov_df['current_state'] = markov_df['pct_change'].apply(lambda x: 1 if x > 0 else 0) # 1 for up, 0 for down\n",
    "markov_df = markov_df.dropna()\n",
    "\n",
    "up_counts   = len(markov_df[markov_df['current_state'] == 1])\n",
    "down_counts = len(markov_df[markov_df['current_state'] == 0])\n",
    "up_to_up    = len(markov_df[(markov_df['current_state'] == 1) & (markov_df['current_state'].shift(-1) == 1)])/up_counts\n",
    "down_to_up  = len(markov_df[(markov_df['current_state'] == 0) & (markov_df['current_state'].shift(-1) == 1)])/down_counts\n",
    "up_to_down  = len(markov_df[(markov_df['current_state'] == 1) & (markov_df['current_state'].shift(-1) == 0)])/up_counts\n",
    "down_to_down= len(markov_df[(markov_df['current_state'] == 0) & (markov_df['current_state'].shift(-1) == 0)])/down_counts\n",
    "\n",
    "transition_matrix = pd.DataFrame({\n",
    "    \"up\": [up_to_up, up_to_down],\n",
    "    \"down\": [down_to_up, down_to_down]\n",
    "}, index=[\"up\", \"down\"])\n",
    "\n",
    "print(transition_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = vbt.Portfolio.from_signals(\n",
    "    markov_df['Close'],\n",
    "    entries=np.where(markov_df['current_state']==1,True,False),\n",
    "    short_entries=np.where(markov_df['current_state']==0,True,False),\n",
    "    td_stop = 1,\n",
    "    time_delta_format = 'rows',\n",
    "    freq = '10T',\n",
    "    # fees = 0.0004,\n",
    ")\n",
    "\n",
    "pf.stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's make this more robust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the thresholds\n",
    "For demonstration purposes, I'll use the 25th and 75th percentiles of the positive and negative pct_change values, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_changes = markov_df[markov_df['pct_change'] > 0]['pct_change']\n",
    "negative_changes = markov_df[markov_df['pct_change'] < 0]['pct_change']\n",
    "\n",
    "small_up_threshold = positive_changes.quantile(0.75)\n",
    "large_up_threshold = positive_changes.quantile(0.80)\n",
    "\n",
    "small_down_threshold = negative_changes.quantile(0.25)\n",
    "large_down_threshold = negative_changes.quantile(0.20)\n",
    "\n",
    "print(f\"Small up threshold: {small_up_threshold}\")\n",
    "print(f\"Large up threshold: {large_up_threshold}\")\n",
    "print(f\"Small down threshold: {small_down_threshold}\")\n",
    "print(f\"Large down threshold: {large_down_threshold}\")\n",
    "\n",
    "def define_state(x):\n",
    "    if x > large_up_threshold:\n",
    "        return \"large_up\"\n",
    "    elif x > 0 and x <= large_up_threshold:\n",
    "        return \"small_up\"\n",
    "    elif x < 0 and x >= large_down_threshold:\n",
    "        return \"small_down\"\n",
    "    elif x < large_down_threshold:\n",
    "        return \"large_down\"\n",
    "\n",
    "markov_df['current_state'] = markov_df['pct_change'].apply(define_state)\n",
    "\n",
    "markov_df['current_state'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the State Definition\n",
    "Now we'll categorize the pct_change values based on the thresholds:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Transition Probabilities\n",
    "Finally, let's update the transition matrix calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"large_up\", \"small_up\", \"small_down\", \"large_down\"]\n",
    "transition_matrix = pd.DataFrame(index=states, columns=states)\n",
    "\n",
    "for from_state in states:\n",
    "    for to_state in states:\n",
    "        from_count = len(markov_df[markov_df['current_state'] == from_state])\n",
    "        \n",
    "        transition_prob = len(markov_df[(markov_df['current_state'] == from_state) & (markov_df['current_state'].shift(-1) == to_state)]) / from_count\n",
    "        transition_matrix.at[from_state, to_state] = transition_prob\n",
    "\n",
    "print(transition_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at a hypothetical simulation of buying after a large_up or shorting after a large_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = vbt.Portfolio.from_signals(\n",
    "    markov_df['Close'],\n",
    "    entries=np.where(markov_df['current_state']=='large_up',True,False),\n",
    "    short_entries=np.where(markov_df['current_state']=='large_down',True,False),\n",
    "    td_stop = 1,\n",
    "    time_delta_format = 'rows',\n",
    "    freq = '10T',\n",
    "    # fees = 0.0004,\n",
    ")\n",
    "\n",
    "pf.stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's move to Higher order Markov Chain Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "order = 3  # you can change this value as needed\n",
    "\n",
    "# drop all columns with future_ or past_ in the name\n",
    "markov_df = markov_df.loc[:, ~markov_df.columns.str.contains('future_|past_')]\n",
    "\n",
    "# Create future state columns for the current state and future states\n",
    "for i in range(1, order):\n",
    "    markov_df[f'future_state{i}'] = markov_df['current_state'].shift(-i)\n",
    "\n",
    "# Create a column for the sequence of future states\n",
    "markov_df['future_sequence'] = markov_df[['current_state'] + [f'future_state{i}' for i in range(1, order)]].apply(lambda row: tuple(row.dropna()), axis=1)\n",
    "\n",
    "# Create past state columns for the current state and previous states\n",
    "for i in range(1, order):\n",
    "    markov_df[f'past_state{i}'] = markov_df['current_state'].shift(i)\n",
    "\n",
    "# Create a column for the sequence of past states\n",
    "markov_df['past_sequence'] = markov_df[['current_state'] + [f'past_state{i}' for i in range(1, order)]].apply(lambda row: tuple(x for x in row if pd.notna(x)), axis=1)\n",
    "\n",
    "# Count transitions for future sequences\n",
    "future_transition_counts = markov_df.groupby('future_sequence')['current_state'].value_counts().unstack().fillna(0)\n",
    "\n",
    "# Calculate transition probabilities for future sequences\n",
    "future_transition_probs = future_transition_counts.div(future_transition_counts.sum(axis=1), axis=0).fillna(0)\n",
    "\n",
    "# Count transitions for past sequences\n",
    "past_transition_counts = markov_df.groupby('past_sequence')['current_state'].value_counts().unstack().fillna(0)\n",
    "\n",
    "# Calculate transition probabilities for past sequences\n",
    "past_transition_probs = past_transition_counts.div(past_transition_counts.sum(axis=1), axis=0).fillna(0)\n",
    "\n",
    "# Order the columns\n",
    "ordered_columns = ['large_up', 'small_up', 'small_down', 'large_down']\n",
    "future_transition_probs = future_transition_probs[ordered_columns]\n",
    "past_transition_probs = past_transition_probs[ordered_columns]\n",
    "\n",
    "# Sort the transition matrices\n",
    "future_transition_probs.sort_index(inplace=True)\n",
    "past_transition_probs.sort_index(inplace=True)\n",
    "\n",
    "# Print the future and past transition matrices\n",
    "print(future_transition_probs)\n",
    "print(past_transition_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def transition_probabilities(markov_df, state_column, sequence_column):\n",
    "    transition_counts = {}\n",
    "    for i, row in markov_df.iterrows():\n",
    "        state = row[state_column]\n",
    "        sequence = row[sequence_column]\n",
    "        if pd.notna(sequence):\n",
    "            if state not in transition_counts:\n",
    "                transition_counts[state] = {}\n",
    "            for seq_state in sequence:\n",
    "                if seq_state not in transition_counts[state]:\n",
    "                    transition_counts[state][seq_state] = 1\n",
    "                else:\n",
    "                    transition_counts[state][seq_state] += 1\n",
    "\n",
    "    print(f\"Transition counts: {transition_counts}\")\n",
    "\n",
    "    transition_probabilities = {}\n",
    "    for state, counts in transition_counts.items():\n",
    "        total = sum(counts.values())\n",
    "        print(f\"State: {state}, Total: {total}\")\n",
    "        probabilities = {seq_state: count / total for seq_state, count in counts.items()}\n",
    "        transition_probabilities[state] = probabilities\n",
    "\n",
    "    return pd.DataFrame(transition_probabilities).fillna(0).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proper code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = 3\n",
    "# drop all columns with future_ or past_ in the name\n",
    "markov_df = markov_df.loc[:,~markov_df.columns.str.contains('future_|past_')]\n",
    "\n",
    "# Create future state columns for the current state and future states\n",
    "for i in range(order):\n",
    "    markov_df[f'future_state{i}'] = markov_df['current_state'].shift(-i)\n",
    "\n",
    "# Generate sequences of future states and count transitions\n",
    "future_states_df = markov_df[[f'future_state{i}' for i in range(order)]]\n",
    "future_transition_counts = future_states_df.groupby([f'future_state{i}' for i in range(order - 1)]).future_state2.value_counts().unstack().fillna(0).astype(int)\n",
    "\n",
    "# Calculate transition probabilities for future sequences\n",
    "future_transition_probs = future_transition_counts.div(future_transition_counts.sum(axis=1), axis=0)\n",
    "\n",
    "# Create past state columns for the current state and previous states\n",
    "for i in range(order):\n",
    "    markov_df[f'past_state{i}'] = markov_df['current_state'].shift(i)\n",
    "\n",
    "# Generate sequences of past states and count transitions\n",
    "past_states_df = markov_df[[f'past_state{i}' for i in range(order)]]\n",
    "past_transition_counts = past_states_df.groupby([f'past_state{i}' for i in range(order - 1)]).past_state2.value_counts().unstack().fillna(0).astype(int)\n",
    "\n",
    "# Calculate transition probabilities for past sequences\n",
    "past_transition_probs = past_transition_counts.div(past_transition_counts.sum(axis=1), axis=0)\n",
    "\n",
    "# Order the columns\n",
    "ordered_columns = ['large_up', 'small_up', 'small_down', 'large_down']\n",
    "future_transition_probs = future_transition_probs[ordered_columns]\n",
    "past_transition_probs = past_transition_probs[ordered_columns]\n",
    "\n",
    "# Sort the transition matrices\n",
    "future_transition_probs.sort_index(inplace=True)\n",
    "past_transition_probs.sort_index(inplace=True)\n",
    "\n",
    "# Print the future and past transition matrices\n",
    "print(future_transition_probs)\n",
    "print(past_transition_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = vbt.Portfolio.from_signals(\n",
    "    markov_df['Close'],\n",
    "    # entries=np.where(markov_df['current_state']==1,True,False),\n",
    "    short_entries=np.where((markov_df['past_state0']=='large_down') & (markov_df['past_state1']=='large_up'),True,False),\n",
    "    td_stop = 1,\n",
    "    time_delta_format = 'rows',\n",
    "    freq = '10T',\n",
    "    # fees = 0.0004,\n",
    ")\n",
    "\n",
    "pf.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order = 3\n",
    "# # drop all columns with future_ or past_ in the name\n",
    "# markov_df = markov_df.loc[:,~markov_df.columns.str.contains('future_|past_')]\n",
    "\n",
    "# # Create future state columns for the current state and future states\n",
    "# for i in range(order):\n",
    "#     markov_df[f'future_state{i}'] = markov_df['current_state'].shift(-i)\n",
    "\n",
    "# # Generate sequences of future states\n",
    "# future_sequences = [tuple(markov_df[[f'future_state{i}' for i in range(order)]].iloc[i].dropna().tolist()) for i in range(len(markov_df) - order + 1)]\n",
    "\n",
    "# # Create past state columns for the current state and previous states\n",
    "# for i in range(order):\n",
    "#     markov_df[f'past_state{i}'] = markov_df['current_state'].shift(i)\n",
    "\n",
    "# # Generate sequences of past states\n",
    "# past_sequences = [tuple(markov_df[[f'past_state{i}' for i in range(order)]].iloc[i].dropna().tolist()) for i in range(len(markov_df) - order + 1)]\n",
    "\n",
    "# # Count transitions for future sequences\n",
    "# future_transition_counts = {}\n",
    "# for seq in future_sequences:\n",
    "#     from_states = seq[:-1]\n",
    "#     to_state = seq[-1]\n",
    "#     from_states_str = ' -> '.join(map(str, from_states))  # Convert to string\n",
    "#     if from_states_str not in future_transition_counts:\n",
    "#         future_transition_counts[from_states_str] = {}\n",
    "#     if to_state not in future_transition_counts[from_states_str]:\n",
    "#         future_transition_counts[from_states_str][to_state] = 0\n",
    "#     future_transition_counts[from_states_str][to_state] += 1\n",
    "\n",
    "# # Calculate transition probabilities for future sequences\n",
    "# future_transition_probs = {}\n",
    "# for from_states_str, to_states in future_transition_counts.items():\n",
    "#     total_counts = sum(to_states.values())\n",
    "#     future_transition_probs[from_states_str] = {to_state: count / total_counts for to_state, count in to_states.items()}\n",
    "\n",
    "# # Convert to DataFrame for future sequences\n",
    "# future_transition_matrix = pd.DataFrame(future_transition_probs).T.fillna(0)\n",
    "\n",
    "# # Order the columns\n",
    "# ordered_columns = ['large_up', 'small_up', 'small_down', 'large_down']\n",
    "# future_transition_matrix = future_transition_matrix[ordered_columns]\n",
    "\n",
    "# # Sort the future transition matrix\n",
    "# future_transition_matrix.sort_index(inplace=True)\n",
    "\n",
    "# # Print the future transition matrix\n",
    "# print(future_transition_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the transition matrix as a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# def plot_transition_matrix_heatmap(transition_matrix, title=\"Transition Matrix Heatmap\"):\n",
    "#     fig, ax = plt.subplots(figsize=(15, 200))\n",
    "#     sns.heatmap(\n",
    "#         transition_matrix.apply(pd.to_numeric, errors='coerce'),  # Convert values to numeric, coercing errors to NaN\n",
    "#         annot=True,\n",
    "#         cmap='coolwarm',\n",
    "#         fmt=\".2f\",\n",
    "#         linewidths=.5,\n",
    "#         ax=ax\n",
    "#     )\n",
    "#     ax.set_title(title)\n",
    "\n",
    "#     # Create a second x-axis at the top of the plot with the same ticks and labels as the main x-axis\n",
    "#     ax2 = ax.twiny()\n",
    "#     ax2.set_xlim(ax.get_xlim())\n",
    "#     ax2.set_xticks(ax.get_xticks())\n",
    "#     ax2.set_xticklabels(ax.get_xticklabels())\n",
    "#     ax2.tick_params(axis='x', direction='in', top=True, bottom=False)\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "# plot_transition_matrix_heatmap(transition_matrix, \"Transition Matrix Heatmap\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences for each order-1 sequence\n",
    "sequence_occurrences = {}\n",
    "for seq in future_sequences:\n",
    "    seq_str = ' -> '.join(seq[:order - 1])  # Convert the first 'order - 1' elements of tuple to string\n",
    "    if seq_str not in sequence_occurrences:\n",
    "        sequence_occurrences[seq_str] = 0\n",
    "    sequence_occurrences[seq_str] += 1\n",
    "\n",
    "# Print the number of occurrences for each order-1 sequence\n",
    "for seq_str, count in sequence_occurrences.items():\n",
    "    print(f'{seq_str}: {count}')\n",
    "\n",
    "# Convert the sequence occurrences to a DataFrame\n",
    "occurrences_df = pd.DataFrame(list(sequence_occurrences.items()), columns=['sequence', 'occurrences'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(occurrences_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_transition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = vbt.Portfolio.from_signals(\n",
    "    markov_df['Close'],\n",
    "    # entries=np.where(markov_df['current_state']==1,True,False),\n",
    "    short_entries=np.where((markov_df['past_state0']=='large_down') & (markov_df['past_state1']=='large_down'),True,False),\n",
    "    td_stop = 1,\n",
    "    time_delta_format = 'rows',\n",
    "    freq = '10T',\n",
    "    # fees = 0.0004,\n",
    ")\n",
    "\n",
    "pf.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = vbt.Portfolio.from_signals(\n",
    "    markov_df['Close'],\n",
    "    # entries=np.where(markov_df['current_state']==1,True,False),\n",
    "    short_entries=np.where((markov_df['past_state0']=='large_down'),True,False),\n",
    "    td_stop = 1,\n",
    "    time_delta_format = 'rows',\n",
    "    freq = '10T',\n",
    "    # fees = 0.0004,\n",
    ")\n",
    "\n",
    "pf.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = vbt.Portfolio.from_signals(\n",
    "    markov_df['Close'],\n",
    "    # entries=np.where(markov_df['current_state']==1,True,False),\n",
    "    short_entries=np.where(\n",
    "        (markov_df['past_state0']=='large_down') & \n",
    "        (markov_df['past_state1']=='large_down') & \n",
    "        (markov_df['past_state2']=='large_down'),\n",
    "        True,False),\n",
    "    td_stop = 1,\n",
    "    time_delta_format = 'rows',\n",
    "    freq = '10T',\n",
    "    # fees = 0.0004,\n",
    ")\n",
    "\n",
    "pf.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.plot().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge transition_matrix and occurrences_df\n",
    "merged_df = future_transition_matrix.merge(\n",
    "    occurrences_df,\n",
    "    left_index=True,\n",
    "    right_on='sequence',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN values in 'count' column with 0\n",
    "merged_df['occurrences'].fillna(0, inplace=True)\n",
    "merged_df.set_index('sequence', inplace=True)\n",
    "# Show the resulting dataframe\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query merged_df where sum of small_down and large_down greater than 0.6 and count greater than 100\n",
    "print(merged_df.query('(small_down + large_down) > 0.65 and occurrences > 100'))\n",
    "print(\"\\nNumber of up squences with a 40% probability: \")\n",
    "print(merged_df.query('(small_up + large_up) > 0.40 and occurrences > 100'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query markov_df where the percent change was negative what percent of the time\n",
    "markov_df.query('pct_change < 0')['pct_change'].count() / markov_df['pct_change'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_transition_matrix_heatmap_with_counts(transition_matrix, title=\"Transition Matrix Heatmap\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 300))\n",
    "\n",
    "    # Plot the transition matrix with probabilities\n",
    "    sns.heatmap(\n",
    "        transition_matrix.iloc[:, :-1],  # Exclude the 'occurrences' column\n",
    "        cmap='coolwarm',\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        linewidths=.5,\n",
    "        ax=ax1,\n",
    "        cbar_kws={'label': 'Probability'}\n",
    "    )\n",
    "    ax1.set_title(title)\n",
    "\n",
    "    # Create a second y-axis sharing the same x-axis\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # Plot the occurrences on the second axis\n",
    "    sns.heatmap(\n",
    "        transition_matrix[['occurrences']],  # Only the 'occurrences' column\n",
    "        cmap='YlGnBu',\n",
    "        annot=True,\n",
    "        fmt=\"d\",  # Integer format\n",
    "        linewidths=.5,\n",
    "        ax=ax2,\n",
    "        cbar_kws={'label': 'Occurrences'}\n",
    "    )\n",
    "\n",
    "    # Hide the second y-axis\n",
    "    ax2.yaxis.set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot the transition matrix with occurrences\n",
    "plot_transition_matrix_heatmap_with_counts(transition_matrix, \"Transition Matrix Heatmap with Counts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a buy or sell signal based on probabilities\n",
    "identify if the probability of a large down or a large up move is high and enter a -1 or 1 in the signal column of the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Number of rows meeting condition for 'sell':\", ((merged_df['large_down'] > 0.2) & (merged_df['occurrences'] > 100)).sum())\n",
    "print(\"Number of rows meeting condition for 'buy':\", ((merged_df['large_up'] > 0.2) & (merged_df['occurrences'] > 100)).sum())\n",
    "\n",
    "\n",
    "columns_to_drop = ['signal_x', 'signal_y', 'signal']\n",
    "for col in columns_to_drop:\n",
    "    if col in markov_df.columns:\n",
    "        markov_df.drop(columns=col, inplace=True)\n",
    "\n",
    "\n",
    "# Define conditions\n",
    "conditions = [\n",
    "    (merged_df['large_down'] > 0.2) & (merged_df['occurrences'] > 100),\n",
    "    (merged_df['large_up'] > 0.2) & (merged_df['occurrences'] > 100)\n",
    "]\n",
    "\n",
    "# Define choices\n",
    "choices = ['sell', 'buy']\n",
    "\n",
    "# Create new column 'signal' with values based on conditions\n",
    "merged_df['signal'] = np.select(conditions, choices, default='hold')\n",
    "\n",
    "# Check if 'signal' column exists in merged_df\n",
    "if 'signal' in merged_df.columns:\n",
    "    print(\"Signal column exists in merged_df\")\n",
    "\n",
    "# Determine the order (number of states) dynamically\n",
    "order = 6\n",
    "print(f\"The Order previously used was {order}\")\n",
    "\n",
    "# Handle NaN values in the state columns\n",
    "for i in range(order):\n",
    "    markov_df[f'past_state{i}'] = markov_df[f'past_state{i}'].fillna('')\n",
    "\n",
    "# Initialize the \"markov_chain\" column with the first past state\n",
    "markov_df['markov_chain'] = markov_df['past_state0']\n",
    "\n",
    "# Concatenate the rest of the past states to \"markov_chain\" column\n",
    "for i in range(1, order - 1):\n",
    "    markov_df['markov_chain'] += ' -> ' + markov_df[f'past_state{i}']\n",
    "\n",
    "# Merge the signals from merged_df to markov_df based on the 'markov_chain'\n",
    "markov_df = markov_df.merge(merged_df[['signal']], left_on='markov_chain', right_index=True, how='left')\n",
    "\n",
    "# Check if 'signal' column exists in markov_df after merge\n",
    "if 'signal' in markov_df.columns:\n",
    "    print(\"Signal column exists in markov_df\")\n",
    "\n",
    "# Handle NaN values in the signal column\n",
    "markov_df['signal'] = markov_df['signal'].fillna('hold')\n",
    "\n",
    "# Display the DataFrame\n",
    "print(merged_df.signal.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'markov_chain' values and index of 'merged_df' to sets\n",
    "markov_chain_values = set(markov_df['markov_chain'])\n",
    "index_values = set(merged_df.index)\n",
    "\n",
    "# Find common values\n",
    "common_values = markov_chain_values.intersection(index_values)\n",
    "\n",
    "# Display number of common values and some examples\n",
    "print(\"Number of common values:\", len(common_values))\n",
    "if len(common_values) > 0:\n",
    "    print(\"Sample common values:\", list(common_values)[:5])\n",
    "else:\n",
    "    print(\"No common values found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_df.signal.value_counts()\n",
    "merged_df.signal.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'signal', 'signal_x', and 'signal_y' columns if they exist\n",
    "columns_to_drop = ['signal', 'signal_x', 'signal_y']\n",
    "for col in columns_to_drop:\n",
    "    if col in markov_df.columns:\n",
    "        markov_df = markov_df.drop(columns=col)\n",
    "\n",
    "# Merge the signals from merged_df to markov_df based on the 'markov_chain'\n",
    "markov_df = markov_df.merge(merged_df[['signal']], left_on='markov_chain', right_index=True, how='left')\n",
    "\n",
    "# Check columns in markov_df after the merge operation\n",
    "print(markov_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_df.iloc[5].markov_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(markov_df['signal']=='buy',True,False).sum())\n",
    "\n",
    "# Sell signals\n",
    "print(np.where(markov_df['signal']=='sell',True,False).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common values between 'markov_chain' in markov_df and the index of merged_df\n",
    "common_values = set(markov_df['markov_chain']).intersection(set(merged_df.index))\n",
    "\n",
    "# Print the number and sample of common values\n",
    "print(\"Number of common values:\", len(common_values))\n",
    "print(\"Sample common values:\", list(common_values)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(markov_df['markov_chain'].dtype)\n",
    "print(merged_df.index.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_df['markov_chain'] = markov_df['markov_chain'].str.strip()\n",
    "merged_df.index = merged_df.index.str.strip()\n",
    "\n",
    "# Perform the merge\n",
    "markov_df = markov_df.merge(merged_df[['signal']], left_on='markov_chain', right_index=True, how='left')\n",
    "\n",
    "# Check for 'buy' and 'sell' signals\n",
    "print(np.where(markov_df['signal']=='buy', True, False).sum())\n",
    "print(np.where(markov_df['signal']=='sell', True, False).sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = vbt.Portfolio.from_signals(\n",
    "    markov_df['Close'],\n",
    "    entries=np.where(markov_df['signal']=='buy',True,False),\n",
    "    short_entries=np.where(markov_df['signal']=='sell',True,False),\n",
    "    td_stop = 1,\n",
    "    time_delta_format = 'rows',\n",
    "    freq = '10T',\n",
    "    # fees = 0.0004,\n",
    ")\n",
    "\n",
    "pf.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.plot().show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
